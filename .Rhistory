load('/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/analysis SNOW/Daymet/metrics calculated w daily data/daymet_monthly_seasonally_2010-2016.RData')
View(cameras)
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(Year %in% my_year,
Julian <= last_day)
View(daymet_data)
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day)
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
left_join(spring)
View(yearly_daymet)
my_year
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
left_join(spring) %>%
na.omit()
View(daymet_data)
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
left_join(spring) %>%
na.omit()
View(spring)
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
select(Camera, year, Julian, Date)# %>%
View(yearly_daymet)
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
select(Camera, year, Julian, Date) %>%
left_join(spring) #%>%
View(yearly_daymet)
View(spring)
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
select(Camera, year, Julian, Date) %>%
left_join(spring) %>%
na.omit()
# Attach to daily data
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
select(Camera, year, Julian, Date) %>%
left_join(spring) %>%
na.omit()
View(yearly_daymet)
# Average by clusters
yearly_daymet1 <- yearly_daymet %>%
group_by(fCluster,Year) %>%
summarise(season_tavg = mean(season_tavg),
season_tmin = mean(season_tmin),
season_tmax = mean(season_tmax)) %>%
mutate(season_tavg =scale(season_tavg),
season_tmin =scale(season_tmin),
season_tmax =scale(season_tmax)) %>%
# works but not ideal
yearly_daymet <- daymet_data %>%
left_join(cams)  %>%
select(fCluster, Date, season_tavg, season_tmin, season_tmax) %>%
filter(fCluster %in% camera_names) %>%
group_by(fCluster,Date) %>%
summarise(season_tavg = mean(season_tavg),
season_tmin = mean(season_tmin),
season_tmax = mean(season_tmax)) %>%
mutate(season_tavg =scale(season_tavg),
season_tmin =scale(season_tmin),
season_tmax =scale(season_tmax)) %>%
mutate(Julian=yday(Date),
Year=year(Date)) %>%
filter(Julian <= last_day) %>%
arrange(fCluster,Year,Julian) #%>%
# Average by clusters
yearly_daymet1 <- yearly_daymet %>%
group_by(fCluster,Year) %>%
summarise(season_tavg = mean(season_tavg),
season_tmin = mean(season_tmin),
season_tmax = mean(season_tmax)) %>%
mutate(season_tavg =scale(season_tavg),
season_tmin =scale(season_tmin),
season_tmax =scale(season_tmax))
# Average by clusters
yearly_daymet1 <- yearly_daymet %>%
group_by(fCluster,year) %>%
summarise(season_tavg = mean(season_tavg),
season_tmin = mean(season_tmin),
season_tmax = mean(season_tmax)) %>%
mutate(season_tavg =scale(season_tavg),
season_tmin =scale(season_tmin),
season_tmax =scale(season_tmax))
View(yearly_daymet1)
View(spring)
# Choose season!
spring <- daymet_data %>%
filter(season==1) %>% # spring is 1
select(Camera, year, season_tavg, season_tmin,season_tmax) %>%
left_join(cams) %>%
na.omit() %>%
group_by(fCluster,year) %>%
summarise(season_tavg = mean(season_tavg),
season_tmin = mean(season_tmin),
season_tmax = mean(season_tmax)) %>%
mutate(season_tavg =scale(season_tavg),
season_tmin =scale(season_tmin),
season_tmax =scale(season_tmax))
View(spring)
# Attach to daily data
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
select(Camera, year, Julian, Date) %>%
left_join(spring) %>%
na.omit()
View(spring)
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
left_join(cams)
View(yearly_daymet)
# Attach to selected daily data
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
left_join(cams) %>%
select(fCluster, year, Julian, Date) %>%
left_join(spring) %>%
na.omit()
View(yearly_daymet)
View(yearly_daymet)
# Attach to selected daily data
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
left_join(cams) %>%
select(fCluster, year, Julian, Date) %>%
left_join(spring) %>%
na.omit() %>%
arrange(fCluster,Date)
# 1. Load hare data
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/hares_cl.RData")
hares <- select(hares_cl, Site, White3, White, Julian, Cluster, Year, fCluster, Camera) %>%
#subset(Julian >200 & Site=="Can")# & Year==2015) # FALL
subset(Julian >50 & Julian <200 & Site=="Can")# & Year==2015) #SPRING
(fClustercount<-length(unique(hares$fCluster)))
# 2. Load camera data (for selected hares data above)
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/cameras.RData")
cameras <- filter(cameras, fCluster %in% camera_names)
camera_names <- unique(hares$fCluster)
(fClustercount <-length(unique(cameras$fCluster)))
# 2. Load camera data (for selected hares data above)
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/cameras.RData")
camera_names <- unique(hares$fCluster)
cameras <- filter(cameras, fCluster %in% camera_names)
(fClustercount <-length(unique(cameras$fCluster)))
ggplot(hares, aes(Julian, White,colour=as.factor(Cluster))) + geom_jitter(width = 1, height = 1) + theme(legend.position = "none")
################################################################################
#  Call a single model step by step - mimics jags_call
#  Set time_scale for the analysis (options are in the column names of hares, Month, Week, Julian)
time_scale <- "Julian"
load.module("glm")
#  Subset to days - to reduce redundancy and ease inits and data create
# unlist makes anything into a vector: here subsetting for one column such as [all rows,column 'Julian']
days <- as.integer(unlist(hares[,time_scale]))
(first_day <- min(days))
(last_day <- max(days))
(my_year <-  as.integer(unique(hares$Year))) # not using currenty for anything
#  Create categorical response
hares$response <- cut(hares$White3, 3, labels = 1:3) # 1 is brown
# used to have: response <- cut(hares$White3, 3, labels = 1:3) (or: response <- ordered(response) to make it ordered but same result)
#### or flip white and brown here if want:
# hares <- mutate(hares, White3_flipped= abs(White3-4))
# hares$response <- cut(hares$White3_flipped, 3, labels = 1:3) # 1 is brown
ggplot(hares, aes(Julian, response, colour=fCluster)) + geom_jitter(width = .1, height = .1) + theme(legend.position = "none")
#  Inits
inits <- function(){
list(
alpha = rnorm(3)
)}
################################
# Yearly daymet data
load('/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/analysis SNOW/Daymet/metrics calculated w daily data/daymet_monthly_seasonally_2010-2016.RData')
cams <- select(cameras, Camera, fCluster, Cluster)
# Choose season and calculate cluster yearly averages
spring <- daymet_data %>%
filter(season==1) %>% # spring is 1
select(Camera, year, season_tavg, season_tmin,season_tmax) %>%
left_join(cams) %>%
na.omit() %>%
group_by(fCluster,year) %>%
summarise(season_tavg = mean(season_tavg),
season_tmin = mean(season_tmin),
season_tmax = mean(season_tmax)) %>%
mutate(season_tavg =scale(season_tavg),
season_tmin =scale(season_tmin),
season_tmax =scale(season_tmax))
# Attach to selected daily data
yearly_daymet <- daymet_data %>%
mutate(Julian=yday(Date)) %>%
filter(year %in% my_year,
Julian <= last_day) %>%
left_join(cams) %>%
select(fCluster, year, Julian, Date) %>%
left_join(spring) %>%
na.omit() %>%
arrange(fCluster,Date)
length(my_year)
#  Multinomial analysis to calculate molt start and end dates
# (and covariates effects) in SSH
# 3 categories of molt
# Random effects on camera traps
#  06/2017
#  Josh Nowak and Marketa Zimova
################################################################################
library(R2jags)
library(readr)
library(purrr)
library(dplyr)
library(beepr)
library(mcmcplots)
library(ggplot2)
library(lubridate)
# 1. Load hare data
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/hares_cl.RData")
hares <- select(hares_cl, Site, White3, White, Julian, Cluster, Year, fCluster, Camera) %>%
#subset(Julian >200 & Site=="Can")# & Year==2015) # FALL
subset(Julian >50 & Julian <200 & Site=="Can")# & Year==2015) #SPRING
(fClustercount<-length(unique(hares$fCluster)))
# 2. Load camera data (for selected hares data above)
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/cameras.RData")
camera_names <- unique(hares$fCluster)
cameras <- filter(cameras, fCluster %in% camera_names)
(fClustercount <-length(unique(cameras$fCluster)))
ggplot(hares, aes(Julian, White,colour=as.factor(Cluster))) + geom_jitter(width = 1, height = 1) + theme(legend.position = "none")
################################################################################
#  Call a single model step by step - mimics jags_call
#  Set time_scale for the analysis (options are in the column names of hares, Month, Week, Julian)
time_scale <- "Julian"
load.module("glm")
#  Subset to days - to reduce redundancy and ease inits and data create
# unlist makes anything into a vector: here subsetting for one column such as [all rows,column 'Julian']
days <- as.integer(unlist(hares[,time_scale]))
(first_day <- min(days))
(last_day <- max(days))
(my_year <-  as.integer(unique(hares$Year))) # not using currenty for anything
#  Create categorical response
hares$response <- cut(hares$White3, 3, labels = 1:3) # 1 is brown
# used to have: response <- cut(hares$White3, 3, labels = 1:3) (or: response <- ordered(response) to make it ordered but same result)
#### or flip white and brown here if want:
# hares <- mutate(hares, White3_flipped= abs(White3-4))
# hares$response <- cut(hares$White3_flipped, 3, labels = 1:3) # 1 is brown
ggplot(hares, aes(Julian, response, colour=fCluster)) + geom_jitter(width = .1, height = .1) + theme(legend.position = "none")
#  Inits
inits <- function(){
list(
alpha = rnorm(3)
)}
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/daymet_2010_2016.RData")
cams <- select(cameras, Camera, fCluster, Cluster)
daymet <- daymet_data %>%
mutate(Julian=yday(Date),
Year=year(Date)) %>%
filter(Julian <= last_day) %>% #but shoud go: Julian>= first_day & Julian <= last_day)
left_join(cams)  %>%
select(fCluster, Julian, tmax, Year) %>%
#filter(fCluster %in% camera_names,
#       Year %in% my_year) %>%
mutate(ClusterYr = paste(fCluster, Year, sep = '_')) %>%
filter(ClusterYr %in% unique(hares$ClusterYr))
spread_daymet <- daymet %>%
group_by(ClusterYr, Julian) %>%
summarise(tmax = mean(tmax, na.rm = T)) %>%
mutate(tmax =scale(tmax)) %>%
ungroup %>%
tidyr::spread(Julian, tmax) %>%
#na.omit() %>% check if any NAs!
arrange(ClusterYr) %>%
select(-ClusterYr) #%>%
#slice(1:172) #to check whether have the right dimensions
#select(-99)  #to check whether have the right dimensions
# should be as wide as #of days 1:200 usually
# should be as long as # of whatever cams is in dat
length(unique(daymet$ClusterYr))
length(unique(hares$ClusterYr))
# # Daily temps
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/daymet_2010_2016.RData")
cams <- select(cameras, Camera, fCluster, Cluster)
daymet <- daymet_data %>%
mutate(Julian=yday(Date),
Year=year(Date)) %>%
filter(Julian <= last_day) %>% #but shoud go: Julian>= first_day & Julian <= last_day)
left_join(cams)  %>%
select(fCluster, Julian, tmax, Year) %>%
#filter(fCluster %in% camera_names,
#       Year %in% my_year) %>%
mutate(ClusterYr = paste(fCluster, Year, sep = '_')) %>%
filter(ClusterYr %in% unique(hares$ClusterYr))
spread_daymet <- daymet %>%
group_by(ClusterYr, Julian) %>%
summarise(tmax = mean(tmax, na.rm = T)) %>%
mutate(tmax =scale(tmax)) %>%
ungroup %>%
tidyr::spread(Julian, tmax) %>%
#na.omit() %>% check if any NAs!
arrange(ClusterYr) %>%
select(-ClusterYr) #%>%
#slice(1:172) #to check whether have the right dimensions
#select(-99)  #to check whether have the right dimensions
# should be as wide as #of days 1:200 usually
# should be as long as # of whatever cams is in dat
length(unique(daymet$ClusterYr))
length(unique(hares$ClusterYr))
hares <- mutate(hares,ClusterYr = paste(fCluster, Year, sep = '_')) %>%
arrange(ClusterYr,Julian)
(ClusterYrcount<-length(unique(hares$ClusterYr)))
# 2. Load camera data (for selected hares data above)
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/cameras.RData")
camera_names <- unique(hares$fCluster)
cameras <- filter(cameras, fCluster %in% camera_names)
(fClustercount <-length(unique(cameras$fCluster)))
ggplot(hares, aes(Julian, White,colour=as.factor(Cluster))) + geom_jitter(width = 1, height = 1) + theme(legend.position = "none")
################################################################################
#  Call a single model step by step - mimics jags_call
#  Set time_scale for the analysis (options are in the column names of hares, Month, Week, Julian)
time_scale <- "Julian"
load.module("glm")
#  Subset to days - to reduce redundancy and ease inits and data create
# unlist makes anything into a vector: here subsetting for one column such as [all rows,column 'Julian']
days <- as.integer(unlist(hares[,time_scale]))
(first_day <- min(days))
(last_day <- max(days))
(my_year <-  as.integer(unique(hares$Year))) # not using currenty for anything
#  Create categorical response
hares$response <- cut(hares$White3, 3, labels = 1:3) # 1 is brown
# used to have: response <- cut(hares$White3, 3, labels = 1:3) (or: response <- ordered(response) to make it ordered but same result)
#### or flip white and brown here if want:
# hares <- mutate(hares, White3_flipped= abs(White3-4))
# hares$response <- cut(hares$White3_flipped, 3, labels = 1:3) # 1 is brown
ggplot(hares, aes(Julian, response, colour=fCluster)) + geom_jitter(width = .1, height = .1) + theme(legend.position = "none")
#  Inits
inits <- function(){
list(
alpha = rnorm(3)
)}
# # Daily temps
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/daymet_2010_2016.RData")
cams <- select(cameras, Camera, fCluster, Cluster)
daymet <- daymet_data %>%
mutate(Julian=yday(Date),
Year=year(Date)) %>%
filter(Julian <= last_day) %>% #but shoud go: Julian>= first_day & Julian <= last_day)
left_join(cams)  %>%
select(fCluster, Julian, tmax, Year) %>%
#filter(fCluster %in% camera_names,
#       Year %in% my_year) %>%
mutate(ClusterYr = paste(fCluster, Year, sep = '_')) %>%
filter(ClusterYr %in% unique(hares$ClusterYr))
spread_daymet <- daymet %>%
group_by(ClusterYr, Julian) %>%
summarise(tmax = mean(tmax, na.rm = T)) %>%
mutate(tmax =scale(tmax)) %>%
ungroup %>%
tidyr::spread(Julian, tmax) %>%
#na.omit() %>% check if any NAs!
arrange(ClusterYr) %>%
select(-ClusterYr) #%>%
#slice(1:172) #to check whether have the right dimensions
#select(-99)  #to check whether have the right dimensions
# should be as wide as #of days 1:200 usually
# should be as long as # of whatever cams is in dat
length(unique(daymet$ClusterYr))
length(unique(hares$ClusterYr))
# 1. Load hare data
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/hares_cl.RData")
hares <- select(hares_cl, Site, White3, White, Julian, Cluster, Year, fCluster, Camera) %>%
#subset(Julian >200 & Site=="Can")# & Year==2015) # FALL
subset(Julian >50 & Julian <200 & Site=="Can")# & Year==2015) #SPRING
(fClustercount<-length(unique(hares$fCluster)))
# If want to run it with daily covariates:
# Create new camera x year identifier
hares <- mutate(hares,ClusterYr = paste(fCluster, Year, sep = '_')) %>%
arrange(ClusterYr,Julian)
(ClusterYrcount<-length(unique(hares$ClusterYr)))
# 2. Load camera data (for selected hares data above)
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/cameras.RData")
camera_names <- unique(hares$fCluster)
cameras <- filter(cameras, fCluster %in% camera_names)
(fClustercount <-length(unique(cameras$fCluster)))
ggplot(hares, aes(Julian, White,colour=as.factor(Cluster))) + geom_jitter(width = 1, height = 1) + theme(legend.position = "none")
################################################################################
#  Call a single model step by step - mimics jags_call
#  Set time_scale for the analysis (options are in the column names of hares, Month, Week, Julian)
time_scale <- "Julian"
load.module("glm")
#  Subset to days - to reduce redundancy and ease inits and data create
# unlist makes anything into a vector: here subsetting for one column such as [all rows,column 'Julian']
days <- as.integer(unlist(hares[,time_scale]))
(first_day <- min(days))
(last_day <- max(days))
(my_year <-  as.integer(unique(hares$Year))) # not using currenty for anything
#  Create categorical response
hares$response <- cut(hares$White3, 3, labels = 1:3) # 1 is brown
# used to have: response <- cut(hares$White3, 3, labels = 1:3) (or: response <- ordered(response) to make it ordered but same result)
#### or flip white and brown here if want:
# hares <- mutate(hares, White3_flipped= abs(White3-4))
# hares$response <- cut(hares$White3_flipped, 3, labels = 1:3) # 1 is brown
ggplot(hares, aes(Julian, response, colour=fCluster)) + geom_jitter(width = .1, height = .1) + theme(legend.position = "none")
#  Inits
inits <- function(){
list(
alpha = rnorm(3)
)}
################################################################################################################################
## Daily daymet temps during 2010-2016
load("/Users/marketzimova/Documents/WORK/DISSERTATION/3 Camera Traps Study/data/daymet_2010_2016.RData")
cams <- select(cameras, Camera, fCluster, Cluster)
daymet <- daymet_data %>%
mutate(Julian=yday(Date),
Year=year(Date)) %>%
filter(Julian <= last_day) %>% #but shoud go: Julian>= first_day & Julian <= last_day)
left_join(cams)  %>%
select(fCluster, Julian, tmax, Year) %>%
#filter(fCluster %in% camera_names,
#       Year %in% my_year) %>%
mutate(ClusterYr = paste(fCluster, Year, sep = '_')) %>%
filter(ClusterYr %in% unique(hares$ClusterYr))
spread_daymet <- daymet %>%
group_by(ClusterYr, Julian) %>%
summarise(tmax = mean(tmax, na.rm = T)) %>%
mutate(tmax =scale(tmax)) %>%
ungroup %>%
tidyr::spread(Julian, tmax) %>%
#na.omit() %>% check if any NAs!
arrange(ClusterYr) %>%
select(-ClusterYr) #%>%
#slice(1:172) #to check whether have the right dimensions
#select(-99)  #to check whether have the right dimensions
# should be as wide as #of days 1:200 usually
# should be as long as # of whatever cams is in dat
length(unique(daymet$ClusterYr))
length(unique(hares$ClusterYr))
####################################################################################
# Gather data
dat <- list(
nobs = nrow(hares),
day = days,
nyr= length(my_year),
#cam = as.numeric(as.factor(hares$fCluster)), #if running with yearly (eg ytemp) or cluster varying covariates (eg elev)
cam = as.numeric(as.factor(hares$ClusterYr)), # if running with daily varying covariates (eg dtemp)
y = hares$response,
nbins = 3,
ndays = last_day,
#ncam = length(unique(hares$fCluster)), # if running with yearly (eg ytemp) or cluster varying covariates (eg elev)
ncam = length(unique(hares$ClusterYr)), # if running with daily varying covariates (eg dtemp)
dtemp = spread_daymet # daily and by camera varying
#elev = as.numeric(GeoCL$ElevSC) # by camera varying
#ytemp = as.numeric(yearly_daymet$ElevSC) # yearly and by camera varying
)
####################################################################################
# Gather data
dat <- list(
nobs = nrow(hares),
day = days,
nyr= length(my_year),
#cam = as.numeric(as.factor(hares$fCluster)), #if running with yearly (eg ytemp) or cluster varying covariates (eg elev)
cam = as.numeric(as.factor(hares$ClusterYr)), # if running with daily varying covariates (eg dtemp)
y = hares$response,
nbins = 3,
ndays = last_day,
#ncam = length(unique(hares$fCluster)), # if running with yearly (eg ytemp) or cluster varying covariates (eg elev)
ncam = length(unique(hares$ClusterYr)), # if running with daily varying covariates (eg dtemp)
dtemp = spread_daymet # daily and by camera varying
#elev = as.numeric(GeoCL$ElevSC) # by camera varying
#ytemp = as.numeric(yearly_daymet$season_tavg) # yearly and by camera varying
)
# Parameters to monitor
parms <- c("beta", "alpha","pp","sigma_cam","tau_cam",
"ytemp","dtemp_eff","elev_eff"#,
#"sigma", "rho", p_rand","cat_mu"
)
#  Call jags
setwd("/Users/marketzimova/Documents/WORK/DISSERTATION/GitHub/multinomial_molt_analysis") #for the model location
start.time <- Sys.time()
out <- jags.parallel( #or just jags
data = dat,
inits = NULL,
parameters.to.save = parms,
model.file = "models/multinom_covs.txt", #works for anything except for ytemp
#model.file = "models/multinom_covs_yr.txt", # for yearly varying covs (=ytemp)
n.chains = 3,
n.iter = 100,
n.burnin = 50,
n.thin = 3
)
